{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run my_import.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plotly(series_dict, labels=None, title=\"Time series\"):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for label, series in series_dict.items():\n",
    "        fig.add_trace(go.Scatter(x=series.index, y=series.values, mode='lines', name=label))\n",
    "    \n",
    "    fig.update_layout(title=title, xaxis_title=\"Data\", yaxis_title=\"Valore\", template=\"plotly_dark\")\n",
    "    # fig.update_layout(include_plotlyjs='cdn')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = {}\n",
    "refresh_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **WHITE NOISE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. White Noise\n",
    "n_years = 10\n",
    "start_date = \"2014-01-01\"\n",
    "series_name = \"White Noise\"\n",
    "date_range = pd.date_range(start=start_date, periods=365*n_years, freq='D')\n",
    "np.random.seed(42)\n",
    "white_noise = np.random.normal(loc=0, scale=1, size=len(date_range))\n",
    "series = pd.Series(white_noise, index=date_range)\n",
    "series_dict[series_name] = series\n",
    "#series.to_csv('wn.csv', index=False)\n",
    "#print(series.tail(10))\n",
    "ts_plotly(series_dict, title=series_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serie storica White Noise dal 2014-01-01 al 2023-12-29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **ENGLAND TEMPERATURE** (messo in pausa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engTemp = loaded_data['EngTemp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SONO DIVERSE STAZIONI METEOROLOGICHE DELL'INGHILTERRA CENTRALE, CON LA TEMPERATURA MEDIA (target) CALCOLATA SU DI ESSE. \\\n",
    "CI SONO DEI NAN CHE ANDRANNO GESTITI.\\\n",
    "LA SERIE VA DAL 01/01/1853 FINO AL 20/03/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **OIL PRICE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_prices = loaded_data['oil_prices']\n",
    "oil_prices.reset_index(inplace=True)\n",
    "oil_prices['date'] = oil_prices['date'].dt.strftime('%Y-%m')\n",
    "oil_prices.set_index('date', inplace=True)\n",
    "oil_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DIMENSIONE:\",oil_prices.shape)\n",
    "print(\"NAN:\",oil_prices.isna().sum())\n",
    "print(\"STATISTICHE DESCRITTIVE:\",oil_price.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF E PACF\n",
    "plot_acf(target, lags=100)\n",
    "plot_pacf(target, lags=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serie storica mensile che va da Marzo 1983 ad Aprile 2025. Abbiamo anche le variazioni, ma questa serie è stata pensata come univariata sul prezzo greggio del petrolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **missing data**: serie univariata delle sales di Favorita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = loaded_data['favorita_train']\n",
    "missing.set_index(\"date\", inplace=True)\n",
    "missing = missing[['sales','family','date']]\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sommo tutte  le vendite per ogni giorno\n",
    "missing = missing.groupby(['date']).sum().reset_index()\n",
    "missing.drop(columns=[\"family\"], inplace=True)\n",
    "missing = missing.rename(columns={\"sales\": \"total_daily_sales\"})\n",
    "missing.set_index(\"date\", inplace=True)\n",
    "ts_plotly({\"sales\": missing['total_daily_sales']}, title=\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF E PACF\n",
    "plot_acf(missing['total_daily_sales'], lags=50)\n",
    "plot_pacf(missing['total_daily_sales'], lags=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **outliers data**: serie univariata delle sales di Favorita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outl = missing.copy()\n",
    "print(\"Dimensione:\",outl.shape)\n",
    "print(\"Quanti NAN ci sono?:\",outl.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo qualche outlier in maniera randomica\n",
    "#metto 5 osservazioni a 3 milioni come valore, DA CAMBIARE !!!!\n",
    "np.random.seed(25)\n",
    "\n",
    "outl_indices = np.random.choice(outl.index, size=5, replace=False)\n",
    "outl.loc[outl_indices, 'total_daily_sales'] = 3000000\n",
    "outl.head()\n",
    "ts_plotly({\"sales\": outl['total_daily_sales']}, title=\"Sales with outliers\")\n",
    "print(\"Dimensione:\",outl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF E PACF\n",
    "plot_acf(outl['total_daily_sales'], lags=40)\n",
    "plot_pacf(outl['total_daily_sales'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **SOLAR ENERGY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SolarData = loaded_data['solar_power']\n",
    "SolarData.set_index('DATE_TIME',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quanti NAN ci sono?:\",SolarData.isna().sum())\n",
    "SolarData.shape\n",
    "print(SolarData.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variabile target sarà la quantità (kW) di corrente **diretta** generata dall'invertitore (pannello --> impianto elettrico), cioè quella in blu. \\\n",
    "Dati ogni 15 minuti, dal 15 Maggio 2020 al 17 Giugno 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_plotly({\n",
    "    'Ambient Temp': SolarData[\"AMBIENT_TEMPERATURE\"], \n",
    "    'Panel Temp': SolarData[\"MODULE_TEMPERATURE\"],\n",
    "}, title='Temperature ambiente VS Temperatura pannello solare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo dataset verrà utilizzato inizialmente per un'analisi univariata della 'Direct current'. Poi, inseriremo dei regressori, fra cui queste due variabili, e la quantità di irradiazione solare (W/m²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggiungo ora del giorno\n",
    "df = SolarData\n",
    "df_reset = df.reset_index()\n",
    "df_reset.rename(columns={'index': 'DATE_TIME'}, inplace=True)\n",
    "df_reset['DATE_TIME'] = pd.to_datetime(df_reset['DATE_TIME'])\n",
    "\n",
    "# Nuove variabili\n",
    "df_reset['ora_del_giorno'] = df_reset['DATE_TIME'].dt.hour + 1\n",
    "\n",
    "df = df_reset.set_index('DATE_TIME')\n",
    "df.head()\n",
    "#plot dela potenza DC vs ora del giorno\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='ora_del_giorno', y='DC_POWER')\n",
    "plt.title('DC Power vs Hour of the Day')\n",
    "plt.xlabel('Hour of the Day')\n",
    "plt.ylabel('DC Power')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AIR QUALITY** (in pausa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con regressori, 7/8k osservazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/AirQualityUCI.csv'\n",
    "aqi = pd.read_csv(file_path, sep=';')\n",
    "aqi.drop(columns=[\"Unnamed: 15\",\"Unnamed: 16\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concateno Date e Time in un'unica nuova colonna DateTime\n",
    "aqi['DateTime'] = pd.to_datetime(aqi['Date'] + ' ' + aqi['Time'], format='%d/%m/%Y %H.%M.%S')\n",
    "# DateTime come indice\n",
    "aqi.set_index('DateTime', inplace=True)\n",
    "\n",
    "# converto colonne Date e Time in datetime\n",
    "aqi['Date'] = pd.to_datetime(aqi['Date'], format='%d/%m/%Y')\n",
    "aqi['Time'] = pd.to_datetime(aqi['Time'], format='%H.%M.%S').dt.time\n",
    "\n",
    "# creo variabili ora del giorno e giorno della settimana\n",
    "aqi['ora_del_giorno'] = pd.to_datetime(aqi['Time'], format='%H:%M:%S').dt.hour + 1\n",
    "aqi['giorno_settimana'] = aqi['Date'].dt.dayofweek + 1\n",
    "\n",
    "# droppo colonne Date e Time\n",
    "aqi.drop(columns=[\"Date\", \"Time\"], inplace=True)\n",
    "aqi.index = pd.DatetimeIndex(pd.to_datetime(aqi.index))\n",
    "#aqi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sostituisco le virgole con il punto e converto in float\n",
    "aqi['CO(GT)'] = aqi['CO(GT)'].astype(str).str.replace(',', '.').astype(float)\n",
    "aqi['C6H6(GT)'] = aqi['C6H6(GT)'].astype(str).str.replace(',', '.').astype(float)\n",
    "aqi['T'] = aqi['T'].astype(str).str.replace(',', '.').astype(float)\n",
    "aqi['RH'] = aqi['RH'].astype(str).str.replace(',', '.').astype(float)\n",
    "aqi['AH'] = aqi['AH'].astype(str).str.replace(',', '.').astype(float)\n",
    "#aqi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_plotly({'CO':aqi['CO(GT)']}, title=\"Air Quality Index\")\n",
    "#i valori -200 sono segnati tali perchè sono NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elimimo (mando a NaN) tutte le celle che contengono un valore minore di 100\n",
    "#nessuna variabile può assumere valore minore di 100\n",
    "aqi1 = aqi[aqi>-100]\n",
    "#aqi1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_plotly unico di NOX, NO2 e CO\n",
    "ts_plotly({\n",
    "    'NOX(GT)':aqi1['NOx(GT)'],\n",
    "    'NO2':aqi1['NO2(GT)'],\n",
    "    'CO':aqi1['CO(GT)']\n",
    "           }, \n",
    "          title=\"Air Quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serie storica con frequenza oraria dal 10/03/2004 al 04/04/2005. Dobbiamo gestire NaN, e scegliere variabili, indipendenti e dipendente. (PCA?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **F1 Race data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NON LANCIARE\n",
    "#Questa dovrebbe essere più veloce, comunque 6/7 minuti\n",
    "fastf1.Cache.enable_cache('cacheF1data')\n",
    "# Carica la sessione\n",
    "session = fastf1.get_session(2023, 'Silverstone', 'R')\n",
    "session.load()\n",
    "\n",
    "# Crea una lista per raccogliere i dati di tutti i piloti\n",
    "all_telemetry = []\n",
    "\n",
    "# Colonne da escludere\n",
    "columns_to_exclude = [\"SessionTime\", \"DriverAhead\", \"Time\", \"Source\", \"Distance\", \n",
    "                     \"RelativeDistance\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "# Itera su tutti i piloti della sessione\n",
    "for drv in session.drivers:\n",
    "    driver_name = session.get_driver(drv)[\"Abbreviation\"]\n",
    "    \n",
    "    # Ottieni i dati di telemetria\n",
    "    laps = session.laps.pick_driver(driver_name)\n",
    "    telemetry = pd.DataFrame()\n",
    "    \n",
    "    for _, lap in laps.iterrows():\n",
    "        lap_telemetry = lap.get_telemetry()\n",
    "        lap_telemetry[\"Driver\"] = driver_name\n",
    "        lap_telemetry[\"LapNumber\"] = lap.LapNumber\n",
    "        \n",
    "        # Rimuovi le colonne non desiderate se presenti\n",
    "        for col in columns_to_exclude:\n",
    "            if col in lap_telemetry.columns:\n",
    "                lap_telemetry = lap_telemetry.drop(columns=[col])\n",
    "        \n",
    "        telemetry = pd.concat([telemetry, lap_telemetry], ignore_index=True)\n",
    "    \n",
    "    all_telemetry.append(telemetry)\n",
    "\n",
    "# Unisci tutti i dati in un unico DataFrame\n",
    "full_telemetry = pd.concat(all_telemetry, ignore_index=True)\n",
    "\n",
    "full_telemetry.to_csv(\"F1_data.csv\", index=False)\n",
    "print(full_telemetry.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.read_csv(\"data\\F1_data.csv\")\n",
    "f1.set_index(\"Date\",inplace=True)\n",
    "#f1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distanza dal pilota davanti\n",
    "series_dict = {\n",
    "    'LEC': f1[f1[\"Driver\"]==\"LEC\"][\"DistanceToDriverAhead\"],\n",
    "    'NOR': f1[f1[\"Driver\"]==\"NOR\"][\"DistanceToDriverAhead\"]}\n",
    "ts_plotly(series_dict, title=\"Distance to Driver Ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RPM del motore\n",
    "series_dict = {\n",
    "    'LEC': f1[f1[\"Driver\"]==\"LEC\"][\"RPM\"],\n",
    "    'NOR': f1[f1[\"Driver\"]==\"NOR\"][\"RPM\"]}\n",
    "ts_plotly(series_dict, title=\"RPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dobbiamo scegliere quale variabile impostare come target. Dati rilevati da sensori all'interno delle autovetture di F1, frequenza variabile dai 50 ai 100 millisecondi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Electricity demand** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/ElecDemand.csv'\n",
    "elec = pd.read_csv(file_path)\n",
    "elec.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midnight_time(date_str):\n",
    "    if len(date_str) < 19:  # Se la stringa è più corta di \"2021-01-01 00:00:00\"\n",
    "        return date_str + \" 00:00:00\"\n",
    "    return date_str\n",
    "\n",
    "elec['Date'] = elec['Date'].apply(add_midnight_time)\n",
    "elec['Date'] = pd.to_datetime(elec['Date'])\n",
    "elec.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = {\n",
    "    'UK Elec Demand': elec[\"Demand\"],\n",
    "    'Workday': elec[\"Workday\"],\n",
    "    'Temp': elec[\"Temperature\"]\n",
    "}\n",
    "ts_plotly(series_dict, title=\"Elec Demand\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding features\n",
    "df_reset = elec.reset_index()\n",
    "df_reset.rename(columns={'Date':'DATE_TIME'}, inplace=True)\n",
    "df_reset['DATE_TIME'] = pd.to_datetime(df_reset['DATE_TIME'])\n",
    "\n",
    "df_reset['giorno_settimana'] = df_reset['DATE_TIME'].dt.dayofweek + 1\n",
    "df_reset['ora_del_giorno'] = df_reset['DATE_TIME'].dt.hour + 1\n",
    "df_reset['settimana_del_mese'] = ((df_reset['DATE_TIME'].dt.day - 1) // 7) + 1\n",
    "df_reset['settimana_del_anno'] = df_reset['DATE_TIME'].dt.isocalendar().week\n",
    "df_reset['giorno_del_mese'] = df_reset['DATE_TIME'].dt.day\n",
    "df_reset['mese_del_anno'] = df_reset['DATE_TIME'].dt.month\n",
    "df_elec = df_reset.set_index('DATE_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 BOXPLOT\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "df_elec.boxplot(column='Demand', by='giorno_settimana', ax=axes[0])\n",
    "axes[0].set_xlabel('Giorno della settimana')\n",
    "axes[0].set_ylabel('Domanda di elettricità')\n",
    "\n",
    "df_elec.boxplot(column='Demand', by='ora_del_giorno', ax=axes[1])\n",
    "axes[1].set_xlabel('Ora del giorno')\n",
    "axes[1].set_ylabel('Domanda di elettricità')\n",
    "\n",
    "df_elec.boxplot(column='Demand', by='mese_del_anno', ax=axes[2])\n",
    "axes[2].set_xlabel(\"Mese dell'anno\")\n",
    "axes[2].set_ylabel('Domanda di elettricità')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Favorita sales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/favorita_train.csv\")\n",
    "test = pd.read_csv(\"data/favorita_test.csv\")\n",
    "train.drop(columns=[\"id\"], inplace=True)\n",
    "test.drop(columns=[\"id\"], inplace=True)\n",
    "train.rename(columns={\"date\":\"DATE_TIME\"}, inplace=True)\n",
    "train['DATE_TIME'] = pd.to_datetime(train['DATE_TIME'], format='%Y-%m-%d')\n",
    "test.rename(columns={\"date\":\"DATE_TIME\"}, inplace=True)\n",
    "test['DATE_TIME']= pd.to_datetime(test['DATE_TIME'], format='%Y-%m-%d')\n",
    "train.set_index(\"DATE_TIME\", inplace=True)\n",
    "test.set_index(\"DATE_TIME\", inplace=True)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot con ts_plotly per store 1 e 50\n",
    "series_dict = {\n",
    "    'Store 50': train[train[\"store_nbr\"]==50][\"sales\"],\n",
    "    'Store 1': train[train[\"store_nbr\"]==1][\"sales\"]\n",
    "    \n",
    "}\n",
    "ts_plotly(series_dict, title=\"Sales Store 1 and Store 50\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 milioni di record. Vendite di alcuni supermercati Favorita in Ecuador. Abbiamo l'identificativo di store, il tipo di prodotto, le vendite totali per un prodotto in uno store in un giorno, e la variabile 'onpromotion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Rossman sales** (in pausa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/ROSSMAN_train.csv', index_col='Date', parse_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = {\n",
    "    'sales store 1':train[train[\"Store\"]==1]['Sales'],\n",
    "    'sales store 2':train[train[\"Store\"]==2]['Sales'],\n",
    "    'sales store 3':train[train[\"Store\"]==3]['Sales']\n",
    "}\n",
    "ts_plotly(series_dict, title=\"Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serie storica delle vednite in 1k+ supermercati Rossman. L'idea è di fare analisi panel con questa e Favorita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = {\n",
    "    'sales store 3':train[train[\"Store\"]==88]['Sales']\n",
    "}\n",
    "ts_plotly(series_dict, title=\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"Store\"]==88].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo utilizzare la serie univariata di un singolo magazzino per outlier/NaN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
